# OpenBB Snowflake AI Agent

This library is a blazingly fast Snowflake connector and streaming AI chat client for use with OpenBB Workspace.

It lets you chat with your data iteratively, and generate validated SQL queries
using natural language.

## Installation

There are no pre-built wheels, so it is currently installable from the source code only.

### Requirements

- Python environment: `>=3.10,<3.14`
- Rust: Cargo must be on `$PATH`
- Maturin: Install in the environment with, `pip install maturin`
- OpenSSL
- SQLCipher

### Steps

With the environment active, and requirements satisfied,
navigate into the root of the project and enter:

```sh
maturin develop
```

This compiles the CPython extension and installs the project in editable mode.
Changes to the Python folder do not require a rebuild, they will be picked up
when `--reload` is used. When changes to the Rust code are made, you must run `maturin develop` again.

## Running

Start the server with:

```sh
uvicorn snowflake_ai.server:app
```

Before running, configure all environment variables.

### Add To Workspace

- Add as a Backend connector.
- Add as an Agent in the Chat interface with the same URL as the Backend.

The action is focused mainly on the chat window, there is only one widget currently.

The `snowlake_execute_query` will accept full SQL statements and return as a table.
This is meant to accept the SQL statements generated by the LLM as copy-paste.

A limit should be applied when returning large amounts of data to avoid overloading
the browser window.

## Environment Variables

### Required

- SNOWFLAKE_USER
- SNOWFLAKE_PASSWORD (P.A.T.)
- SNOWFLAKE_ACCOUNT
- SNOWFLAKE_ROLE

### Optional

- SNOWFLAKE_WAREHOUSE
- SNOWFLAKE_DATABASE
- SNOWFLAKE_SCHEMA
- SNOWFLAKE_CACHE (absolute path to a SQLite3 database)
  - This holds conversation history, tool outputs, and other context objects.
  - If None, an in-memory cache is used.
- SNOWFLAKE_CACHE_KEY (Must be supplied for file-based caches.)

Generate a secure, random key using: `openssl rand -base64 32`

### Debug

- SNOWFLAKE_DEBUG

Setting this will stream the SSE output to the console,
along with other debug messages.

## Features

### âš™ï¸ Slash Commands

Slash (`/`) commands provide a way to define model settings at the conversation level,
explore the available Snowflake databases, and manage context.

#### Model Management:

- `/models` - List available AI models
- `/model <name>` - Switch to a different model
- `/temperature <0.0-1.0>` - Set response temperature
- `/max_tokens <number>` - Set max response tokens

#### Session Information:

- `/current` - Show current session info (database, model config, usage stats)
- `/history` - Show conversation history summary

#### Database Navigation:

- `/databases` - List all databases
- `/schemas [database]` - List schemas (optionally in specific database)
- `/tables` - List tables in current database.schema
- `/warehouses` - List available warehouses
- `/stages` - List available stages
- `/stage_files <stage_name>` - List files in a stage

#### Context Switching:

These commands help the conversation flow easier by narrowing the focus.

- `/use_database <name>` - Switch to a different database
- `/use_schema <name>` - Switch to a different schema
- `/use_warehouse <name>` - Switch to a different warehouse

#### Conversation Management:

- `/clear` - Clear conversation history (all messages)

#### SQL Assistance:

- `/complete <partial_query>` - Complete a partial SQL query

You can ask me to generate, validate, and execute queries to any database and table accessible.

### ðŸ§  Conversation History

I maintain a structured record of all messages in the current chat session â€” including:

- User messages
- My responses
- Tool calls and their raw results (e.g., Snowflake query outputs, table definitions)
- System-level instructions and configuration details (like model behavior)

This allows me to recall everything thatâ€™s been done without re-running queries or asking redundant questions.

I can always describe:

- Which tools were invoked
- What data they returned
- What operations were performed (e.g., listing tables, retrieving schemas)
- The total number of messages and stored tool results

If the `SNOWFLAKE_CACHE` environment variable is not set to a location,
this will be done in-memory and will not be preserved on server restart.

### ðŸ§© Context Management Tools

I have built-in mechanisms for:

- Context recall: I can look back at any previous message, including tool results.
- Context compression: When the conversation grows large, I can selectively condense nonessential dialogue while preserving all data and instructions.
- Context clearing: You can remove the message history to start fresh by using, `/clear`.
- Context inspection: You can ask `/history` or `/current` to view whatâ€™s stored, including message counts, tool calls, and token usage.

You can manage context directly:

- `/history` â†’ Lists all messages, tool calls, and operations in the conversation.
- `/current` â†’ Shows current context settings, token usage, and model configuration.
- `/clear` â†’ Resets context (starts fresh).
- `/help` â†’ Lists all system-level commands.

Hereâ€™s how I use these capabilities intelligently:

- Preservation of tool outputs: I never summarize or paraphrase raw Snowflake data â€” those are always kept verbatim in context.
- Selective recall: When answering new queries, I reference only relevant prior data (e.g., a specific table definition or query result).
- Compression for efficiency: When token usage grows, I shorten conversational context but maintain all schema and data references.
- Continuity across tasks: I use earlier results (like column definitions) to validate later SQL transformations without needing to re-run them.
